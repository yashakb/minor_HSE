{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Семинар по деревьям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Берем данные boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(boston[\"data\"], boston[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.DataFrame(X_tr, columns=boston[\"feature_names\"])\n",
    "data_test = pd.DataFrame(X_te, columns=boston[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Далее мы будем реализовывать первый шаг в построении решающего дерева - выбор признака и порога для разделения в корне дерева. Мы будем писать максимально понятный, но не оптимальный, код, т. е. в sklearn все реализовано более эффективно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# чтобы было удобно сортировать объекты вместе с целевым вектором, допишем его в датафрейм\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# чтобы было удобно перебирать порог на первый признак, сортируем датафрейм по нему\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# считаем качество - дисперсию ответов в левом и правом поддереве с весами, как в лекции\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# рисуем график порог - качество разделения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Чем меньше, тем лучше, поэтому оптимум остигается где-то в CRIM = 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Теперь сделаем это для каждого признака (copypaste - это очень плохо, но для демонстрации хорошо).\n",
    "\n",
    "Обратите внимание: чтобы было удобно сравнивать значение критерия для разных признаков, мы все рисуем на одном графике. Но шкала (множество значений) у каждого признака своя. Так что мы будем откладывать по оси x просто числа от 0 до длины выборки, и величину оптимального порога по графику будет определить нельзя. По графику мы сможем определить только оптимальный признак для разделения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for feat in data_train.columns[:-1]:\n",
    "    # code for one feature here\n",
    "plt.legend(loc=(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Кажется, выиграл RM. Нарисуем для него график отдельно (уже с его осью): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Величина порога:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "thresh = data_train[feat][np.argmin(quals)]\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Нарисуем выборку в осях RM - target и изобразим порог, по которому мы разделили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_train[\"RM\"], data_train[\"target\"])\n",
    "plt.plot([thresh, thresh], [0, 60], color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Видно, что точки справа от красной линии лежат почти все выше 30, а слева - ниже, т. е. этот признак действительно очень хорошо разделяет выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Критерий останова построения дерева\n",
    "\n",
    "Очевидно, для любой обучающей выборки можно построить решающее дерево, которое имеет нулевую ошибку на данной выборке. Однако в этом случае имеет место **переобучение**.\n",
    "\n",
    "В связи с этим встаёт вопрос: в каком случае вершину следует объявить листовой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Рассмотрим модельную задачу регрессии. Объектами будут являться точки на плоскости (т.е. каждый объект описывается 2 признаками), целевой переменной — расстояние от объекта до точки (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1. Все объекты в вершине относятся к одному к классу.\n",
    "\n",
    "    Простое условие, но приводит к переобучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2. При дальнейшем разбиении выборки глубина дерева превысит допустимую максимальную глубину.\n",
    "#### 3. При дальнейшем разбиении количество объектов в листьях станет меньше допустимого порога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for i, max_depth in enumerate([2, 4, None]):\n",
    "    for j, min_samples_leaf in enumerate([1, 5, 15]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((3, 3), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='spring')\n",
    "        plt.title('max_depth=' + str(max_depth) + ', min_samples_leaf: ' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Можно увидеть, что увеличение глубины дерева и уменьшение количества объектов в листьях способствует гибкости модели и, как следствие, переобучению. \n",
    "\n",
    "#### 4. Стрижка деревьев (pruning)\n",
    "Все предыдущие критерии останова были направлены против построения переобученного дерева. При использовании прунинга сначала строится максимально переобученное дерево, после чего оно усовершенствуется путем удаления некоторых листовых вершин. Данный способ работает лучше, чем рассмотренные ранее, однако является более трудоёмким."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Неустойчивость решающих деревьев\n",
    "\n",
    "Решающие деревья — это алгоритмы, неустойчивые к изменениям обучающей выборки, т.е. при малейших её изменениях итоговый классификатор может радикально измениться.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    indecies = np.random.randint(data_x.shape[0], size=(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indecies], data_y[indecies])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Решающие леса\n",
    "\n",
    "Чтобы уменьшить влияние рассмотренных недостатков решающих деревьев, используют **случайные леса (random forest)**. Одно дерево может ошибаться, поэтому давайте построим много деревьев и \"усредним\" их ответы.\n",
    "\n",
    "Если строить все эти леса по одной и той же обучающей выборке, они будут одинаковые, поэтому для каждого решающего дерева, которое мы строим:\n",
    "* вместо исходной обучающей выборки $X^l$ используется бутстрап (т.е. выборка $l$ объектов **с возвращениями**);\n",
    "* в каждой внутренней вершине выбор условия осуществляется не среди всех признаков, а среди $q$ случайно выбранных.\n",
    "\n",
    "Такая рандомизация обеспечит нам различность деревьев. После того, как таким образом были получены алгоритмы $b_1(x), ... b_N(x)$ можно построить итоговый алгоритм как:\n",
    "* **выбор большинства** в случае классификации: $a(x) = \\arg \\max_{y in \\mathbb{Y}} \\sum_{n=1}^N [b_n(x) = y]$\n",
    "* **среднее** в случае регрессии: $a(x) = \\frac{1}{N} \\sum_{n = 1}^N b_n(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i, n in enumerate([1, 2, 10]):\n",
    "    clf = RandomForestRegressor(n_estimators=n, random_state=42)\n",
    "    clf.fit(data_x, data_y)\n",
    "    xx, yy = get_grid(data_x)\n",
    "    \n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    \n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='autumn')\n",
    "    \n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='autumn')\n",
    "    plt.title('estimators: %i' % n)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
